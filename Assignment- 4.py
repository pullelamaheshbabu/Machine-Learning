# -*- coding: utf-8 -*-
"""icp4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1__iYgaeVQ0JGZJT_2Cc5EHXC6tWCMH6K
"""



import pandas as pd
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

# Load the CC dataset
cc_data = pd.read_csv('CC GENERAL.csv')

# Drop any non-numeric columns and handle missing values
cc_data = cc_data.select_dtypes(include=[float, int]).dropna()

# Sample a subset of the data
cc_data_sampled = cc_data.sample(n=1000, random_state=42)

# Apply PCA
scaler = StandardScaler()
cc_scaled = scaler.fit_transform(cc_data_sampled)
pca = PCA(n_components=2)
cc_pca = pca.fit_transform(cc_scaled)

# Apply k-means algorithm on the PCA result
kmeans = KMeans(n_clusters=3, random_state=42)
cc_kmeans = kmeans.fit_predict(cc_pca)

# Calculate silhouette score
silhouette_avg = silhouette_score(cc_pca, cc_kmeans)
print(f'Silhouette Score after PCA: {silhouette_avg}')

# Perform Scaling + PCA + K-Means
kmeans_scaled = KMeans(n_clusters=3, random_state=42)
cc_kmeans_scaled = kmeans_scaled.fit_predict(cc_scaled)

# Calculate silhouette score for scaled data
silhouette_avg_scaled = silhouette_score(cc_scaled, cc_kmeans_scaled)
print(f'Silhouette Score after Scaling + PCA + K-Means: {silhouette_avg_scaled}')

import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load the pd_speech_features dataset
speech_data = pd.read_csv('pd_speech_features.csv')

# Separate features and target
X_speech = speech_data.drop(columns=['class'])
y_speech = speech_data['class']

# Perform Scaling
scaler = StandardScaler()
X_speech_scaled = scaler.fit_transform(X_speech)

# Apply PCA (k=3)
pca = PCA(n_components=3)
X_speech_pca = pca.fit_transform(X_speech_scaled)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_speech_pca, y_speech, test_size=0.2, random_state=42)

# Use SVM to report performance
svm = SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'SVM Accuracy after PCA (k=3): {accuracy}')

import pandas as pd
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

# Load the Iris dataset
iris_df = pd.read_csv("Iris.csv")

# Separate features and target
X = iris_df.iloc[:, :-1]  # all columns except the last one
y = iris_df.iloc[:, -1]   # the last column

# Apply Linear Discriminant Analysis (LDA)
lda = LDA(n_components=2)
X_lda = lda.fit_transform(X, y)

# Create a new DataFrame with the LDA results
lda_df = pd.DataFrame(X_lda, columns=['LD1', 'LD2'])
lda_df['target'] = y

# Save the transformed dataset to a new CSV file
lda_df.to_csv("Iris_LDA.csv", index=False)